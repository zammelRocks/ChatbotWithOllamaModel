import express from 'express';
import cors from 'cors';
import { HfInference } from "@huggingface/inference";

const app = express();
const port = 3003;
const client = new HfInference("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");

app.use(cors());
app.use(express.json()); // Middleware to parse JSON body

app.post('/generate', async (req, res) => {
    const { prompt, max_tokens } = req.body;

    if (!prompt) {
        return res.status(400).json({ error: "Prompt is required" });
    }

    try {
        // Sending the chat prompt to Hugging Face model and receiving response
        const chatCompletion = await client.chatCompletion({
            model: "mistralai/Mistral-Nemo-Instruct-2407",
            messages: [
                {
                    role: "user",
                    content: prompt
                }
            ],
            max_tokens: max_tokens || 500
        });

        // Send back the response generated by the model
        res.json({ response: chatCompletion.choices[0].message.content });
    } catch (error) {
        console.error(error);
        res.status(500).json({ error: "Error generating response", details: error.message });
    }
});

app.listen(port, () => {
    console.log(`API running on http://localhost:${port}`);
});
